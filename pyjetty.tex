\documentclass[12pt]{article}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{geometry}
\usepackage{color}
\usepackage{verbatimbox}
\geometry{margin=2cm}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

\usepackage{url}
\usepackage{tcolorbox}
\usepackage{multirow}
\usepackage{float}

\usepackage{setspace}
\onehalfspacing

\newcommand\tab[1][1cm]{\hspace*{#1}}


\title{Using pyjetty}
\author{Reynier Cruz Torres}

\begin{document}

\maketitle

\tableofcontents

% ========================================================================================
\newpage
\section{Processing}

Example on running a local pp data job:

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
python process/user/rey/process_data_energy_drop.py \
-f /rstorage/alice/data/LHC17pq/448/20-06-2020/448_20200619-0610/unmerged/child_1/0001/AnalysisResults.root \
-c config/energy_drop/rey_pp.yaml
\end{verbnobox}  
\end{tcolorbox}

Example on running a local pp mc job:
\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
python process/user/rey/process_mc_energy_drop.py \
-f /rstorage/alice/data/LHC18b8/520/child_1/TrainOutput/1/282008/0001/AnalysisResults.root \
-c config/energy_drop/rey_pp.yaml
\end{verbnobox}  
\end{tcolorbox}

Example on running a slurm data job:
\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
cd slurm/sbatch/energy_drop/
sbatch slurm_LHC17pq.sh
\end{verbnobox}  
\end{tcolorbox}

% ========================================================================================
\section{Merging data root files}

\begin{itemize}
\item \verb|cd| \verb|pyjetty/pyjetty/alice_analysis/slurm/utils/rey|
\item open the file \verb|merge_data.sh|

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
#! /bin/bash
#
# Script to merge output ROOT files

JOB_ID=209383

FILE_DIR="/rstorage/alice/AnalysisResults/rey/$JOB_ID"
FILES=$( find "$FILE_DIR" -name "*.root" )

OUTPUT_DIR=/rstorage/alice/AnalysisResults/rey/$JOB_ID
hadd -f -j 20 $OUTPUT_DIR/AnalysisResultsFinal.root $FILES
\end{verbnobox}  
\end{tcolorbox}

\item edit this file and replace \verb|rey| with your username and edit the number in \verb|JOB_ID=209383| with the correct run number that you would like to merge
\item \verb|source merge_data.sh|
\end{itemize}

% ========================================================================================
\section{Scaling and merging MC root files}
\label{sec:scale_merge}

The MC files are produced separate in $\hat{p}_T$ bins. This is done to focus the generation in different bins
and accrue similar amount of statistics even in the bins where the cross section is small. Consequently, these files need to be scaled by the cross section
before combining them.

\begin{enumerate}
\item hadd all root files corresponding to the same $\hat{p}_T$ bin.
See, for example: \href{https://github.com/reynier0611/pyjetty/blob/master/pyjetty/alice_analysis/slurm/utils/rey/slurm_merge_LHC18b8.sh}{slurm\_merge\_LHC18b8.sh} and
\href{https://github.com/reynier0611/pyjetty/blob/master/pyjetty/alice_analysis/slurm/utils/rey/merge_LHC18b8.sh}{merge\_LHC18b8.sh}.
Edit both files and replace \verb|rey| with the appropriate username. Also, modify the number in \verb|JOB_ID=209384| in \verb|merge_LHC18b8.sh| to reflect the right job number.

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
sbatch slurm_merge_LHC18b8.sh
\end{verbnobox}  
\end{tcolorbox}

\item cd into the directory containing the 1/, 2/, ... sub-directories and scale the combined files corresponding to a given $\hat{p}_T$ bin by the appropriate scale factor.
To do so, run scaleHistograms.py (with the correct file path) and config file associated with the simulation, e.g. -c /rstorage/alice/data/LHC18b8/scaleFactors.yaml.
Here's an example:

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
python /home/rey/pyjetty/pyjetty/alice_analysis/slurm/utils/rey/scaleHistograms.py \
-c /rstorage/alice/data/LHC18b8/scaleFactors.yaml
\end{verbnobox}  
\end{tcolorbox}

The path given above is specifically for the PYTHIA8 + GEANT3 simulations. The paths for the fast PYTHIA8 and fast HERWIG7 simulations are:

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
/rstorage/generators/pythia_alice/tree_fastsim/scaleFactors.yaml
/rstorage/generators/herwig_alice/tree_fastsim/scaleFactors.yaml
\end{verbnobox}  
\end{tcolorbox}

respectively.

In the case of the HERWIG7 fast simulation, we observed some outliers. To clean them, do:

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
python /home/rey/pyjetty/pyjetty/alice_analysis/slurm/utils/rey/scaleHistograms_fastHerwig.py
\end{verbnobox}  
\end{tcolorbox}

after the previous step.

\item After the histograms have been scaled, you should merge the $\hat{p}_T$ bins. See for example \href{https://github.com/reynier0611/pyjetty/blob/master/pyjetty/alice_analysis/slurm/utils/rey/merge_pthat.sh}{merge\_pthat.sh}.
The number in the line \verb|JOB_ID=209384| and paths should be updated. Then do:

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
source merge_pthat.sh
\end{verbnobox}  
\end{tcolorbox}

\end{enumerate}

% ========================================================================================
\section{Analysis}

\subsection{Writing analysis code}

You need to begin by creating a code in: \verb|pyjetty/pyjetty/alice_analysis/analysis/user/|.
This code will inherit from
\href{https://github.com/reynier0611/pyjetty/blob/master/pyjetty/alice_analysis/analysis/user/substructure/run_analysis.py}{/substructure/run\_analysis.py}.
For an example analysis code see: \href{https://github.com/reynier0611/pyjetty/blob/master/pyjetty/alice_analysis/analysis/user/rey/run_analysis_energy_drop.py}{run\_analysis\_energy\_drop.py}.

\subsubsection{Functions the user needs to implement}

There are three main functions the user needs to implement in the analysis code:

\begin{itemize}
\item \verb|plot_single_result()|
\item \verb|plot_all_results()|
\item \verb|plot_performance()|
\end{itemize}

The function names are self-explanatory.

You also need to edit two functions in \href{https://github.com/reynier0611/pyjetty/blob/master/pyjetty/alice_analysis/analysis/user/substructure/analysis_utils_obs.py}{analysis/user/substructure/analysis\_utils\_obs.py}:

\verb|formatted_subobs_label| and \verb|prior_scale_factor_obs|.

\subsection{Running analysis code}

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
python analysis/user/rey/run_analysis_energy_drop.py  -c config/energy_drop/rey_pp.yaml
\end{verbnobox}  
\end{tcolorbox}

\subsection{What happens when you run the analysis code}

Right away, what the code does is it runs the `main' function \href{https://github.com/reynier0611/pyjetty/blob/master/pyjetty/alice_analysis/analysis/user/substructure/run_analysis.py#L223}{run\_analysis()} defined in \verb|run_analysis.py|.
The first step in this function is to do unfolding (if the user requested it) through the function \href{https://github.com/reynier0611/pyjetty/blob/master/pyjetty/alice_analysis/analysis/user/substructure/run_analysis.py#L257}{perform\_unfolding()},
also defined in \verb|run_analysis.py|.

This function loops over the `systematic' settings defined in the config file. For each setting, the code sets variables related to inputs and outputs:

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
output_dir = getattr(self, `output_dir_{}'.format(systematic))
data = self.main_data
response = self.main_response

main_response_location = os.path.join(getattr(self, `output_dir_main'), `response.root')
rebin_response = self.check_rebin_response(output_dir)
\end{verbnobox}  
\end{tcolorbox}

It the initializes some variables:

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
prior_variation_parameter = 0.
truncation = False
binning = False
R_max =  self.R_max
prong_matching_response = False
\end{verbnobox}  
\end{tcolorbox}

And it finally sets these variables depending on the systematic setting to be unfolded:

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
if systematic == `trkeff':
   response = self.trkeff_response
elif systematic == `prior1':
   prior_variation_parameter = self.prior1_variation_parameter
elif systematic == `prior2':
   prior_variation_parameter = self.prior2_variation_parameter
elif systematic == `truncation':
   truncation = True
elif systematic == `binning':
   binning = True
elif systematic == `subtraction1':
   R_max = self.R_max1
elif systematic == `subtraction2':
   R_max = self.R_max2
elif systematic == `prong_matching':
   prong_matching_response = True
\end{verbnobox}  
\end{tcolorbox}

Once these variables have been properly set, the code
\href{https://github.com/reynier0611/pyjetty/blob/master/pyjetty/alice_analysis/analysis/user/substructure/run_analysis.py#L292}{creates an instance of the Roounfold\_Obs class}, and subsequently
runs the function \href{https://github.com/reynier0611/pyjetty/blob/master/pyjetty/alice_analysis/analysis/user/substructure/run_analysis.py#L297}{roounfold\_obs()}.

\subsubsection{Unfolding}

The \verb|Roounfold_Obs| class and the \verb|roounfold_obs()| function are defined in \href{https://github.com/reynier0611/pyjetty/blob/master/pyjetty/alice_analysis/analysis/user/substructure/roounfold_obs.py}{roounfold\_obs.py}.
 
When the instance of the \verb|Roounfold_Obs| class is created, the function \verb|create_output_dirs()| is called. This function creates the following directories:
`RM', `Data', `KinematicEfficiency', `Unfolded\_obs', `Unfolded\_pt', `Unfolded\_ratio', `Unfolded\_stat\_uncert', `Test\_StatisticalClosure', `Test\_Refolding', `Correlation\_Coefficients' and
if the variable \verb|thermal_model| is true, `Test\_ThermalClosure'.
Also, two directories called `Test\_ShapeClosure\{\}' are created. Here, \{\} corresponds to the prior variation parameters defined at the bottom of the config file (with periods removed).
For instance, if the config file has:

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
prior1_variation_parameter: 0.5
prior2_variation_parameter: -0.5
\end{verbnobox}  
\end{tcolorbox}

then you will get the directories `Test\_ShapeClosure-05' and `Test\_ShapeClosure05'.

The unfolding procedure is done two-dimensionally in the observable and in $p_{\rm T}$.
The response matrix corresponds to:

\begin{equation}
\Lambda = (p_{\rm T, det}, p_{\rm T, true}, {\rm observable_{det}}, {\rm observable_{true}}).
\end{equation}
This matrix is then used to unfold the data using Bayes' theorem:

\begin{equation}
P(T|O,\Lambda) = \frac{P(O|T,\Lambda) \cdot P(T)}{P(O)},
\end{equation}
where $P(T|O,\Lambda)$ is the likelihood of the truth ($T$) occurring given that the observation ($O$) is true.
Similarly, $P(O|T,\Lambda)$ is the likelihood of $O$ occurring given that $T$ is true.
$P(T)$ and $P(O)$ are the marginal probabilities of observing $T$ and $O$, respectively.

\subsubsection{Unfolding tests}

During the unfolding procedure, three validation tests are carried out:

\begin{enumerate}
\item {\bf Refolding test:} the Response Matrix (RM) is multiplied by the unfolded result, and compared to the original detector-level distribution.
This is done in roounfold\_obs.py in the \verb|refolding_test| function. Before doing the refolding, the kinematic-efficiency correction is reverted.
Then, the output plots are created in \verb|plot_obs_refolded_slice|. In these plots, the folded truth level and the detector-level (i.e. pre-unfolding) data are compared.

\item {\bf Statistical closure test:}

\begin{itemize}
\item MC det-level is smeared by an amount equal to the measured statistical uncertainty
\item the smeared det-level MC is then unfolded
\item unfolded smeared MC is compared to MC truth-level
\end{itemize}

This test checks whether the unfolding procedure is insensitive to statistical fluctuations of the measured spectra.
This is done in roounfold\_obs.py in the \verb|statistical_closure_test| function.
Then, the output plots are created in \verb|plot_obs_closure_slice|.

\item {\bf Shape closure test:}

\begin{itemize}
\item MC det-level and MC truth-level spectra are scaled
\item scaled MC det-level spectrum is unfolded
\item MC truth-level and unfolded scaled MC det-level spectra are compared
\end{itemize}

This test checks whether the unfolding procedure is insensitive to the 
shape of the measured distribution.
This is done in roounfold\_obs.py in the \verb|shape_closure_test| function, which calls the
\verb|shape_closure_test_single| function twice, once with each shape-variation parameter.
Then, the output plots are created in \verb|plot_obs_closure_slice|.

\subsubsection{Kinematic efficiency}

The kinematic efficiency is calculated in \href{https://github.com/reynier0611/pyjetty/blob/master/pyjetty/alice_analysis/analysis/user/substructure/roounfold_obs.py}{roounfold\_obs.py} in the \verb|plot_kinematic_efficiency| function.
1D slices are plotted in \verb|plot_kinematic_efficiency_projections|. In the case of the jet axis analysis, this is defined as:

\begin{equation}
\varepsilon_{\rm kin}(\Delta R_{\rm true} , p_{\rm T, true}) \equiv \frac{\frac{dN}{d\Delta R_{\rm true}}\big(\Delta R_{\rm det}\in \big[0,R/2\big],p_{\rm T, det} \in \big[10,80\big]\big)}{\frac{dN}{d\Delta R_{\rm true}}\big(\Delta R_{\rm det}\in \big[0,R/2\big],p_{\rm T, det} \in \big[0,\infty\big]\big)}
\end{equation}

\end{enumerate}

\subsection{Systematic Uncertainties}

By default, pyjetty extracts the following sources of systematics:

\begin{itemize}
\item track efficiency
\item regularization parameter
\item priors 1, 2
\item truncation
\item binning
\end{itemize}

The explanation for each of these systematics is given below.

\subsubsection{Track efficiency}

The uncertainty on the tracking efficiency is approximately $4\%$ for hybrid tracks \cite{Alice_AN_534,Alice_AN_818,james,ezra}.
To assign a systematic uncertainty that accounts for this effect, we construct a response matrix by randomly rejecting $4\%$ of tracks in jet finding.
The resulting response matrix is then used to unfold the data.

\subsubsection{Regularization parameter}
\subsubsection{Priors 1, 2}
\subsubsection{Truncation}
\subsubsection{Binning}

% ========================================================================================
\section{Generating PYTHIA events within heppy}

I will use the jet-axis analysis as an example. \\
cd into \verb|pyjetty/pyjetty/alice_analysis/slurm/sbatch/jet_axis| and do:

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
sbatch pythia_gen_jet_axis_slurm.sh
\end{verbnobox}  
\end{tcolorbox}

This shell script is running jobs over the code: \\ \verb|pyjetty/pyjetty/alice_analysis/process/user/rey/pythia_parton_hadron.py|
After the jobs are finished, cd into: \verb|/home/rey/pyjetty/pyjetty/alice_analysis/slurm/utils/rey/gen/|. 
To merge the subjobs for each pT-bins, edit the run number in \verb|merge_pythia.sh|, and then do:

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
sbatch slurm_merge_pythia.sh
\end{verbnobox}  
\end{tcolorbox}

If people are using the cluster and you cannot wait, then do this last step locally by editing the run number in \verb|local_merge_gen.sh|, and then doing:

\begin{tcolorbox}
\begin{verbnobox}[\scriptsize]
source sourceme_local_merge_gen.sh
\end{verbnobox}  
\end{tcolorbox}

Finally, merge the different pT-hat-bin files using the same method described in the last step of section~\ref{sec:scale_merge}.
No scaling is needed, since this is already done in the \verb|pythia_parton_hadron.py| code.


% ========================================================================================

\bibliography{bib_file}
\bibliographystyle{ieeetr}

\end{document}





